{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW2_(3)_(1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVvo3D7wXNP-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58b4db61-b2bd-438d-a25a-cecf8514e982"
      },
      "source": [
        "#Q1\n",
        "\"\"\"\n",
        "We use our custom function to approximate the sine function.\n",
        "\"\"\"\n",
        "\n",
        "import torch\n",
        "import math\n",
        "\n",
        "\n",
        "class CustomFunction(torch.autograd.Function):\n",
        "    @staticmethod\n",
        "    def forward(ctx, input):\n",
        "        ctx.save_for_backward(input)\n",
        "        return 0.5 * (5 * input ** 3 - 3 * input)\n",
        "\n",
        "    @staticmethod\n",
        "    def backward(ctx, grad_output):\n",
        "        input, = ctx.saved_tensors\n",
        "        return grad_output\n",
        "\n",
        "\n",
        "dtype = torch.float\n",
        "device = torch.device(\"cuda:0\")\n",
        "\n",
        "x = torch.linspace(-math.pi, math.pi, 2000, device=device, dtype=dtype)\n",
        "y = torch.sin(x) # We approximate this sine function.\n",
        "\n",
        "# In our model, we have 4 weights to train: y = a + b * P3(c + d * x).\n",
        "# These weights need to be initialized.\n",
        "# Setting requires_grad=True indicates that we want to compute gradients with\n",
        "# respect to these Tensors during the backward pass.\n",
        "a = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "b = torch.full((), -1.0, device=device, dtype=dtype, requires_grad=True)\n",
        "c = torch.full((), 0.0, device=device, dtype=dtype, requires_grad=True)\n",
        "d = torch.full((), 0.3, device=device, dtype=dtype, requires_grad=True)\n",
        "\n",
        "learning_rate = 5e-6\n",
        "for t in range(2000):\n",
        "    P3 = CustomFunction.apply\n",
        "\n",
        "    # Forward pass: predict y.\n",
        "    # P3 using our custom backward function.\n",
        "    y_pred = a + b * P3(c + d * x)\n",
        "\n",
        "    # Compute and print loss\n",
        "    loss = (y_pred - y).pow(2).sum()\n",
        "    if t % 100 == 99:\n",
        "        print(t, loss.item())\n",
        "\n",
        "    # Use autograd to compute the backward pass.\n",
        "    loss.backward()\n",
        "\n",
        "    # Update weights using gradient descent\n",
        "    with torch.no_grad():\n",
        "        a -= learning_rate * a.grad\n",
        "        b -= learning_rate * b.grad\n",
        "        c -= learning_rate * c.grad\n",
        "        d -= learning_rate * d.grad\n",
        "\n",
        "        # Manually zero the gradients after updating weights\n",
        "        a.grad = None\n",
        "        b.grad = None\n",
        "        c.grad = None\n",
        "        d.grad = None        \n",
        "\n",
        "print(f'Result: y = {a.item()} + {b.item()} * P3({c.item()} + {d.item()} x)')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "99 1051.36669921875\n",
            "199 891.9246826171875\n",
            "299 869.5606079101562\n",
            "399 856.9406127929688\n",
            "499 848.6029663085938\n",
            "599 842.5750122070312\n",
            "699 848.6878662109375\n",
            "799 842.6385498046875\n",
            "899 849.3232421875\n",
            "999 843.1123657226562\n",
            "1099 849.3018188476562\n",
            "1199 843.0963745117188\n",
            "1299 849.290771484375\n",
            "1399 843.0882568359375\n",
            "1499 849.9043579101562\n",
            "1599 843.5435791015625\n",
            "1699 850.6546630859375\n",
            "1799 844.0972900390625\n",
            "1899 851.34814453125\n",
            "1999 844.60595703125\n",
            "Result: y = -8.150967401032716e-11 + -0.02794724516570568 * P3(-2.2004557898025467e-10 + -0.7375721335411072 x)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cpa9uc5lo7lt"
      },
      "source": [
        "def custom_kernel1(X, Y):\n",
        "  # Polynomial(homogeneous)\n",
        "  # (X * Y)^d\n",
        "  out = (np.dot(X, Y.T)) ** 2\n",
        "  return out"
      ],
      "execution_count": 285,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TLbT4LZQ2fyo"
      },
      "source": [
        "def custom_kernel2(X, Y):\n",
        "  # Polynomial(inhomogeneous)\n",
        "  # (X * Y + c)^d\n",
        "  out = (np.dot(X, Y.T) + 5) ** 2\n",
        "  return out"
      ],
      "execution_count": 286,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZS3MJGoa24fH"
      },
      "source": [
        "def custom_kernel3(X, Y):\n",
        "  # Gaussian radial basis function(RBF)\n",
        "  # exp(-gamma * (magnitude(x-y))^2)\n",
        "  gamma = 1/2\n",
        "  temp = np.square(X[:, np.newaxis] - Y).sum(axis=2)\n",
        "  out = np.exp(-gamma * temp)\n",
        "  return out"
      ],
      "execution_count": 287,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GnxVhxCUGZjT"
      },
      "source": [
        "def custom_kernel4(X, Y):\n",
        "  # Hyperbolic tangent(sigmoid)\n",
        "  # tanh(k * X * Y + c)\n",
        "  out = np.tanh(1 / 250 * np.dot(X,Y.T) - 2)\n",
        "  return out"
      ],
      "execution_count": 288,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hLpzKcepW62N"
      },
      "source": [
        "def custom_kernel5(X, Y):\n",
        "  # Linear\n",
        "  # X * Y + c\n",
        "  out = np.dot(X, Y.T) + 1\n",
        "  return out"
      ],
      "execution_count": 289,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKQp5b_XYOqK"
      },
      "source": [
        "def custom_kernel6(X, Y):\n",
        "  # Cosine kernel\n",
        "  # (X * Y) / (magnitude(X) * magnitude(Y))\n",
        "  out = np.dot(X, Y.T) / (np.linalg.norm(X, axis=1)[:,np.newaxis] * np.linalg.norm(Y, axis=1))\n",
        "  return out"
      ],
      "execution_count": 290,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kz2sxbbXZdY_"
      },
      "source": [
        "def custom_kernel7(X, Y):\n",
        "  # Multiquadric kernel\n",
        "  # sqrt(magnitude(X-Y)^2 + c^2)\n",
        "  temp = np.square(X[:, np.newaxis] - Y).sum(axis=2)\n",
        "  out = np.sqrt(temp + 500 ** 2)\n",
        "  return out "
      ],
      "execution_count": 291,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Efu292E_vpNO"
      },
      "source": [
        "def custom_kernel8(X, Y):\n",
        "  # Log kernel\n",
        "  # -log((X-Y)^d + 1)\n",
        "  temp = ((X[:, np.newaxis] - Y) ** 2).sum(axis=2) + 1\n",
        "  out = -np.log(temp)\n",
        "  return out"
      ],
      "execution_count": 292,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU4zGHwrv3uu"
      },
      "source": [
        "def custom_kernel9(X, Y):\n",
        "  # Cauchy kernel\n",
        "  # 1 / (1 + magnitude((X-Y)^2) / sigma^2)\n",
        "  temp = np.square(X[:, np.newaxis] - Y).sum(axis=2)\n",
        "  out = 1 / (1 + temp / (13**2))\n",
        "  return out"
      ],
      "execution_count": 293,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1bT5ZqxAv3_D"
      },
      "source": [
        "def custom_kernel10(X, Y):\n",
        "  # Tstudent kernel\n",
        "  # 1 / (1 + (magnitude(X-Y))^d)\n",
        "  temp = ((X[:, np.newaxis] - Y) ** 3).sum(axis=2)\n",
        "  out = 1 / (1 + temp)\n",
        "  return out"
      ],
      "execution_count": 294,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdLZSJjaY2r8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbd485a2-b7b1-4819-9da4-b0b5d508b244"
      },
      "source": [
        "#Q2\n",
        "\"\"\"\n",
        "We will implement many custom kernels. Try to improve the classification accuracy and F-1 scores.\n",
        "\"\"\"\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "import sklearn\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "#You must use a random state of 2011 for this homework.\n",
        "X = (pd.read_csv(\"trainX.csv\")).values\n",
        "Y = (pd.read_csv(\"trainY.csv\")).values\n",
        "XTe = (pd.read_csv(\"testX.csv\")).values\n",
        "YTe = (pd.read_csv(\"testY.csv\")).values\n",
        "\n",
        "#clf = SVC(random_state=2011)\n",
        "clf = SVC(random_state=2011, kernel=custom_kernel6)\n",
        "clf.fit(X, Y)\n",
        "yp = clf.predict(XTe)\n",
        "print(accuracy_score(YTe, yp))\n",
        "print(f1_score(YTe, yp, average='macro'))\n",
        "\n",
        "# The version of sklearn should be \"0.22.2.post1\" for reproducibility.\n",
        "print(sklearn.__version__)"
      ],
      "execution_count": 295,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5128205128205128\n",
            "0.4914207275223061\n",
            "0.22.2.post1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
            "  y = column_or_1d(y, warn=True)\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}