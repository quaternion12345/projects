{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "localization_kcrossval_new.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-cm7T_YaCPUo"
      },
      "source": [
        "# Data "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-04T06:28:45.735825Z",
          "iopub.status.busy": "2020-08-04T06:28:45.735556Z",
          "iopub.status.idle": "2020-08-04T06:28:46.719294Z",
          "shell.execute_reply": "2020-08-04T06:28:46.718590Z",
          "shell.execute_reply.started": "2020-08-04T06:28:45.735797Z"
        },
        "id": "sIHKtMxJCPUn"
      },
      "source": [
        "import torch\n",
        "torch.set_default_dtype(torch.float64)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import torch.optim as optim\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMx8Ji0lDE3j",
        "outputId": "4dc20d2a-84c6-4d32-ccf6-edf0ef1dfb02"
      },
      "source": [
        "import os\n",
        "!wget https://raw.githubusercontent.com/quaternion12345/lora/main/20210514.csv\n",
        "os.rename(r'20210514.csv',r'rssi_data.csv')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-21 06:28:07--  https://raw.githubusercontent.com/quaternion12345/lora/main/20210514.csv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17334 (17K) [text/plain]\n",
            "Saving to: ‘20210514.csv’\n",
            "\n",
            "\r20210514.csv          0%[                    ]       0  --.-KB/s               \r20210514.csv        100%[===================>]  16.93K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-05-21 06:28:07 (121 MB/s) - ‘20210514.csv’ saved [17334/17334]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-04T06:31:24.626059Z",
          "iopub.status.busy": "2020-08-04T06:31:24.625787Z",
          "iopub.status.idle": "2020-08-04T06:31:24.645890Z",
          "shell.execute_reply": "2020-08-04T06:31:24.645055Z",
          "shell.execute_reply.started": "2020-08-04T06:31:24.626031Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "zT4FqPIxCPUo",
        "outputId": "19eebd79-9b28-475d-9b0a-b39847363235"
      },
      "source": [
        "rssi_data_df = pd.read_csv(\"rssi_data.csv\",index_col=0)\n",
        "rssi_data_df.head(n=10)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rssi.242</th>\n",
              "      <th>rssi.94</th>\n",
              "      <th>rssi.h</th>\n",
              "      <th>rssi.245</th>\n",
              "      <th>outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>-83</td>\n",
              "      <td>-101</td>\n",
              "      <td>-73</td>\n",
              "      <td>-74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>-84</td>\n",
              "      <td>-99</td>\n",
              "      <td>-74</td>\n",
              "      <td>-75</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>-83</td>\n",
              "      <td>-101</td>\n",
              "      <td>-69</td>\n",
              "      <td>-74</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>-85</td>\n",
              "      <td>-100</td>\n",
              "      <td>-69</td>\n",
              "      <td>-75</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>-83</td>\n",
              "      <td>-103</td>\n",
              "      <td>-68</td>\n",
              "      <td>-73</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>-86</td>\n",
              "      <td>-93</td>\n",
              "      <td>-63</td>\n",
              "      <td>-81</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>-86</td>\n",
              "      <td>-92</td>\n",
              "      <td>-63</td>\n",
              "      <td>-80</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>-84</td>\n",
              "      <td>-94</td>\n",
              "      <td>-62</td>\n",
              "      <td>-81</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>-85</td>\n",
              "      <td>-92</td>\n",
              "      <td>-62</td>\n",
              "      <td>-81</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>-85</td>\n",
              "      <td>-94</td>\n",
              "      <td>-62</td>\n",
              "      <td>-81</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    rssi.242  rssi.94  rssi.h  rssi.245  outcome\n",
              "1        -83     -101     -73       -74        1\n",
              "2        -84      -99     -74       -75        1\n",
              "3        -83     -101     -69       -74        1\n",
              "4        -85     -100     -69       -75        1\n",
              "5        -83     -103     -68       -73        1\n",
              "6        -86      -93     -63       -81        1\n",
              "7        -86      -92     -63       -80        1\n",
              "8        -84      -94     -62       -81        1\n",
              "9        -85      -92     -62       -81        1\n",
              "10       -85      -94     -62       -81        1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4UQftUSCPUp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34e74eec-7dbd-44f5-9102-3fcb1b94fb4d"
      },
      "source": [
        "max(rssi_data_df[\"rssi.242\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-60"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "frvMrTanCPUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28c043ef-0216-47d9-c3b6-281a9ec2a510"
      },
      "source": [
        "np.mean(rssi_data_df[\"rssi.242\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-73.19654714475432"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8oAndksCPUq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c770602-5d72-4ae2-b570-0fd144b2d1a2"
      },
      "source": [
        "rssi_data_df.info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "Int64Index: 753 entries, 1 to 753\n",
            "Data columns (total 5 columns):\n",
            " #   Column    Non-Null Count  Dtype\n",
            "---  ------    --------------  -----\n",
            " 0   rssi.242  753 non-null    int64\n",
            " 1   rssi.94   753 non-null    int64\n",
            " 2   rssi.h    753 non-null    int64\n",
            " 3   rssi.245  753 non-null    int64\n",
            " 4   outcome   753 non-null    int64\n",
            "dtypes: int64(5)\n",
            "memory usage: 35.3 KB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syI2UHuhCPUs"
      },
      "source": [
        "# Dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "execution": {
          "iopub.execute_input": "2020-08-04T06:29:06.741545Z",
          "iopub.status.busy": "2020-08-04T06:29:06.741263Z",
          "iopub.status.idle": "2020-08-04T06:29:06.748525Z",
          "shell.execute_reply": "2020-08-04T06:29:06.747632Z",
          "shell.execute_reply.started": "2020-08-04T06:29:06.741517Z"
        },
        "id": "U2VAu2zGCPUt"
      },
      "source": [
        "class DenseModel(nn.Module):\n",
        "    def __init__(self, num_in):\n",
        "\n",
        "        super(DenseModel, self).__init__()\n",
        "\n",
        "        self.fc1 = nn.Linear(num_in, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256, 128)\n",
        "        self.fc4 = nn.Linear(128, 64)\n",
        "        self.ouput = nn.Linear(64, 11)\n",
        "        #self.dropout = F.dropout(p=0.5)\n",
        "        #self.dropout = nn.Dropout(p=0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.gelu(self.fc1(x))\n",
        "        x = F.gelu(self.fc2(x))\n",
        "        x = F.gelu(self.fc3(x))\n",
        "        x = F.gelu(self.fc4(x))\n",
        "\n",
        "        #x = F.dropout(torch.sigmoid(self.fc3(x)), p=0.5)\n",
        "        x = self.ouput(x)\n",
        "        return x\n",
        "\n",
        "dense = DenseModel(4)\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t66jhTCdaCnp"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "def reset_weights(m):\n",
        "  '''\n",
        "    Try resetting model weights to avoid\n",
        "    weight leakage.\n",
        "  '''\n",
        "  for layer in m.children():\n",
        "   if hasattr(layer, 'reset_parameters'):\n",
        "    print(f'Reset trainable parameters of layer = {layer}')\n",
        "    layer.reset_parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZRsWbVobl_N",
        "outputId": "a40a6012-0e80-4265-a925-64f1912d5a1e"
      },
      "source": [
        "# 훈련, 테스트 데이터 shuffle & split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "TEST_PERCENTAGE = 0.2\n",
        "train, test = train_test_split(rssi_data_df, test_size=TEST_PERCENTAGE)\n",
        "print('train data length:',len(train))\n",
        "print('test data length:',len(test))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train data length: 602\n",
            "test data length: 151\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfPUmzL1nraq"
      },
      "source": [
        "###################################\n",
        "# You can skip this train process #\n",
        "# Just download trained model     #\n",
        "################################### "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvbuWjAwaQsK"
      },
      "source": [
        "# Configuration options\n",
        "k_folds = 5\n",
        "num_epochs = 250\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# For fold results\n",
        "results = {}\n",
        "\n",
        "# Set fixed random number seed\n",
        "torch.manual_seed(42)\n",
        "\n",
        "kfold = KFold(n_splits=k_folds, shuffle=True)\n",
        "dataset = train.values # TensorFlow/Keras likes numpy/arrays rather than Dataframes"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HU-cJQvgarHP"
      },
      "source": [
        "# K-fold Cross Validation model evaluation\n",
        "#network = DenseModel(4)\n",
        "\n",
        "for fold, (train_ids, test_ids) in enumerate(kfold.split(dataset)):\n",
        "  \n",
        "  # Print\n",
        "  print(f'FOLD {fold}')\n",
        "  print('--------------------------------')\n",
        "  \n",
        "  # Sample elements randomly from a given list of ids, no replacement.\n",
        "  train_subsampler = torch.utils.data.SubsetRandomSampler(train_ids)\n",
        "  test_subsampler = torch.utils.data.SubsetRandomSampler(test_ids)\n",
        "  \n",
        "  # Define data loaders for training and testing data in this fold\n",
        "  trainloader = torch.utils.data.DataLoader(\n",
        "                    dataset, \n",
        "                    batch_size=10, sampler=train_subsampler)\n",
        "  testloader = torch.utils.data.DataLoader(\n",
        "                    dataset,\n",
        "                    batch_size=10, sampler=test_subsampler)\n",
        "  \n",
        "  # Init the neural network\n",
        "  network = DenseModel(4)\n",
        "  network.apply(reset_weights)\n",
        "\n",
        "  \n",
        "  # Initialize optimizer\n",
        "  optimizer = torch.optim.Adam(network.parameters(), lr=0.001)\n",
        "  \n",
        "  # Run the training loop for defined number of epochs\n",
        "  for epoch in range(0, num_epochs):\n",
        "\n",
        "    # Print epoch\n",
        "    print(f'Starting epoch {epoch+1}')\n",
        "\n",
        "    # Set current loss value\n",
        "    current_loss = 0.0\n",
        "\n",
        "    # Iterate over the DataLoader for training data\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs = data[:,:4]\n",
        "      targets = data[:,4]\n",
        "      # Zero the gradients\n",
        "      optimizer.zero_grad()\n",
        "      \n",
        "      # Perform forward pass\n",
        "      outputs = network(inputs.double())\n",
        "      \n",
        "      # Compute loss\n",
        "      loss = loss_function(outputs, targets)\n",
        "      \n",
        "      # Perform backward pass\n",
        "      loss.backward()\n",
        "      \n",
        "      # Perform optimization\n",
        "      optimizer.step()\n",
        "      \n",
        "      # Print statistics\n",
        "      current_loss += loss.item()\n",
        "      if i % 10 == 0:\n",
        "          print('Loss after mini-batch %5d: %.3f' %\n",
        "                (i + 1, current_loss / 500))\n",
        "          current_loss = 0.0\n",
        "          \n",
        "  # Process is complete.\n",
        "  print('Training process has finished. Saving trained model.')\n",
        "\n",
        "  # Print about testing\n",
        "  print('Starting testing')\n",
        "\n",
        "  # Saving the model\n",
        "  save_path = f'./model-fold-{fold}.pth'\n",
        "  torch.save(network.state_dict(), save_path)\n",
        "\n",
        "  # Evaluation for this fold\n",
        "  correct, total = 0, 0\n",
        "  with torch.no_grad():\n",
        "\n",
        "    # Iterate over the test data and generate predictions\n",
        "    for i, data in enumerate(testloader, 0):\n",
        "\n",
        "      # Get inputs\n",
        "      inputs = data[:,:4]\n",
        "      targets = data[:,4]\n",
        "\n",
        "      # Generate outputs\n",
        "      outputs = network(inputs.double())\n",
        "\n",
        "      # Set total and correct\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      total += targets.size(0)\n",
        "      correct += (predicted == targets).sum().item()\n",
        "\n",
        "    # Print accuracy\n",
        "    print('Accuracy for fold %d: %d %%' % (fold, 100.0 * correct / total))\n",
        "    print('--------------------------------')\n",
        "    results[fold] = 100.0 * (correct / total)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x8PofQAsguqf",
        "outputId": "58d2474d-9d18-4b01-985b-5d205f2691ec"
      },
      "source": [
        "# Print fold results\n",
        "print(f'K-FOLD CROSS VALIDATION RESULTS FOR {k_folds} FOLDS')\n",
        "print('--------------------------------')\n",
        "sum = 0.0\n",
        "for key, value in results.items():\n",
        "  print(f'Fold {key}: {value} %')\n",
        "  sum += value\n",
        "print(f'Average: {sum/len(results.items())} %')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "K-FOLD CROSS VALIDATION RESULTS FOR 5 FOLDS\n",
            "--------------------------------\n",
            "Fold 0: 88.42975206611571 %\n",
            "Fold 1: 89.25619834710744 %\n",
            "Fold 2: 86.66666666666667 %\n",
            "Fold 3: 88.33333333333333 %\n",
            "Fold 4: 85.0 %\n",
            "Average: 87.53719008264463 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "25aNJnhHlzCm",
        "outputId": "8ebb7f44-54aa-4990-d91f-d234bed29109"
      },
      "source": [
        "#######################################\n",
        "# download best model from repository #\n",
        "#######################################\n",
        "!wget https://raw.githubusercontent.com/quaternion12345/lora/main/models/94p/model-fold-0.pth\n",
        "!wget https://raw.githubusercontent.com/quaternion12345/lora/main/models/94p/model-fold-1.pth\n",
        "!wget https://raw.githubusercontent.com/quaternion12345/lora/main/models/94p/model-fold-2.pth\n",
        "!wget https://raw.githubusercontent.com/quaternion12345/lora/main/models/94p/model-fold-3.pth\n",
        "!wget https://raw.githubusercontent.com/quaternion12345/lora/main/models/94p/model-fold-4.pth"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-05-21 06:27:10--  https://raw.githubusercontent.com/quaternion12345/lora/main/models/94p/model-fold-0.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1409545 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘model-fold-0.pth’\n",
            "\n",
            "\rmodel-fold-0.pth      0%[                    ]       0  --.-KB/s               \rmodel-fold-0.pth    100%[===================>]   1.34M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-05-21 06:27:10 (24.5 MB/s) - ‘model-fold-0.pth’ saved [1409545/1409545]\n",
            "\n",
            "--2021-05-21 06:27:10--  https://raw.githubusercontent.com/quaternion12345/lora/main/models/94p/model-fold-1.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1409545 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘model-fold-1.pth’\n",
            "\n",
            "model-fold-1.pth    100%[===================>]   1.34M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-21 06:27:11 (23.8 MB/s) - ‘model-fold-1.pth’ saved [1409545/1409545]\n",
            "\n",
            "--2021-05-21 06:27:11--  https://raw.githubusercontent.com/quaternion12345/lora/main/models/94p/model-fold-2.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1409545 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘model-fold-2.pth’\n",
            "\n",
            "model-fold-2.pth    100%[===================>]   1.34M  --.-KB/s    in 0.06s   \n",
            "\n",
            "2021-05-21 06:27:11 (23.1 MB/s) - ‘model-fold-2.pth’ saved [1409545/1409545]\n",
            "\n",
            "--2021-05-21 06:27:11--  https://raw.githubusercontent.com/quaternion12345/lora/main/models/94p/model-fold-3.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1409545 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘model-fold-3.pth’\n",
            "\n",
            "model-fold-3.pth    100%[===================>]   1.34M  --.-KB/s    in 0.05s   \n",
            "\n",
            "2021-05-21 06:27:12 (26.0 MB/s) - ‘model-fold-3.pth’ saved [1409545/1409545]\n",
            "\n",
            "--2021-05-21 06:27:12--  https://raw.githubusercontent.com/quaternion12345/lora/main/models/94p/model-fold-4.pth\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1409545 (1.3M) [application/octet-stream]\n",
            "Saving to: ‘model-fold-4.pth’\n",
            "\n",
            "model-fold-4.pth    100%[===================>]   1.34M  --.-KB/s    in 0.03s   \n",
            "\n",
            "2021-05-21 06:27:12 (46.1 MB/s) - ‘model-fold-4.pth’ saved [1409545/1409545]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rDFrr8lIO7Pt"
      },
      "source": [
        "m0 = DenseModel(4)\n",
        "m1 = DenseModel(4)\n",
        "m2 = DenseModel(4)\n",
        "m3 = DenseModel(4)\n",
        "m4 = DenseModel(4)\n",
        "m0.load_state_dict(torch.load('/content/model-fold-0.pth'))\n",
        "m1.load_state_dict(torch.load('/content/model-fold-1.pth'))\n",
        "m2.load_state_dict(torch.load('/content/model-fold-2.pth'))\n",
        "m3.load_state_dict(torch.load('/content/model-fold-3.pth'))\n",
        "m4.load_state_dict(torch.load('/content/model-fold-4.pth'))\n",
        "\n",
        "m = [m0,m1,m2,m3,m4]"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t6AWYfy0kNPf",
        "outputId": "8e6da3e4-47a5-42eb-91a0-9473439416ce"
      },
      "source": [
        "# 테스트 데이터셋 각 모델에 대해 돌려보기\n",
        "out = []\n",
        "for i in range(5):\n",
        "  correct, total = 0, 0\n",
        "  with torch.no_grad():\n",
        "    # Get inputs\n",
        "    inputs = torch.DoubleTensor(test.values[:,:4])\n",
        "    targets = torch.DoubleTensor(test.values[:,4])\n",
        "\n",
        "    # Generate outputs\n",
        "    out.append(m[i](inputs.double()))\n",
        "\n",
        "    # Set total and correct\n",
        "    _, predicted = torch.max(out[i].data, 1)\n",
        "    total += targets.size(0)\n",
        "    correct += (predicted == targets).sum().item()\n",
        "\n",
        "    # Print accuracy\n",
        "    print('Test Accuracy for model %d: %d %%' % (i, 100.0 * correct / total))\n"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy for model 0: 93 %\n",
            "Test Accuracy for model 1: 92 %\n",
            "Test Accuracy for model 2: 94 %\n",
            "Test Accuracy for model 3: 90 %\n",
            "Test Accuracy for model 4: 89 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9jmNS_emwt1",
        "outputId": "6c364b11-5d00-4508-d786-f310791565dd"
      },
      "source": [
        "# 모델 앙상블\n",
        "out_avg = (out[0] + out[1] + out[2] + out[3] + out[4]) / 5.\n",
        "_, predicted = torch.max(out_avg.data, 1)\n",
        "\n",
        "# accuracy 측정\n",
        "targets = torch.DoubleTensor(test.values[:,4])\n",
        "\n",
        "correct, total = 0, 0\n",
        "total += targets.size(0)\n",
        "correct += (predicted == targets).sum().item()\n",
        "\n",
        "# 틀린 것들만 출력\n",
        "print('Wrong Predictions: (Predicted / Ground Truth)')\n",
        "for i in range(targets.size(0)):\n",
        "  if predicted[i].item()!=int(targets[i].item()):\n",
        "    print(predicted[i].item(), int(targets[i].item()))\n",
        "    \n",
        "# Print accuracy\n",
        "print('--------------------------------')\n",
        "print('Test Accuracy for model ensemble: %d %%' % (100.0 * correct / total))\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wrong Predictions: (Predicted / Ground Truth)\n",
            "7 10\n",
            "7 6\n",
            "5 6\n",
            "6 7\n",
            "7 6\n",
            "5 7\n",
            "6 4\n",
            "6 7\n",
            "7 6\n",
            "--------------------------------\n",
            "Test Accuracy for model ensemble: 94 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}